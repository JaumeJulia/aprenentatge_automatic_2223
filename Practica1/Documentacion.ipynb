{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Práctica 1 - Clasificación de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos\n",
    "En esta primera parte de la práctica vamos a preparar los datos para poder hacer la clasificación. Para ello haremos que cada muestra siga el siguiente formato: C1 | C2 | C3 | .. | CN | Y  (siendo C una característica y Y el target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.to_string of           word       y\n",
      "0      suggest  angles\n",
      "1         came  angles\n",
      "2      planeta  catala\n",
      "3     finestra  catala\n",
      "4        saber  catala\n",
      "...        ...     ...\n",
      "1971       box  angles\n",
      "1972     ready  angles\n",
      "1973      amic  catala\n",
      "1974   believe  angles\n",
      "1975        am  angles\n",
      "\n",
      "[1976 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "#Auxiliar function that reformats df to one that is more fitting to Classification Problems\n",
    "def reformat(dataFrame):\n",
    "    dataFrame['y']=dataFrame.columns[0]\n",
    "    dataFrame.rename(columns={dataFrame.columns[0]: 'word'}, inplace=True)\n",
    "    return dataFrame;\n",
    "#RawData, it has been a little bit formatted before reading the csv, to facilitate the process.\n",
    "raw=pd.read_csv(\"data/data.csv\")\n",
    "#Split df\n",
    "catala, angles= raw.filter(['catala'], axis=1), raw.filter(['angles'], axis=1)\n",
    "#Reformating\n",
    "catala=reformat(catala)\n",
    "angles=reformat(angles)\n",
    "\n",
    "#Merging\n",
    "wordsDF=pd.concat([catala,angles], axis=0)\n",
    "#Shuffle the rows\n",
    "wordsDF = wordsDF.sample(frac=1).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caracterísiticas\n",
    "Las características que hemos pensado que pueden ser útiles para la clasificación de las palabras son:\n",
    "- Cantidad de caracteres (Númerica)\n",
    "- Proporción de consonantes por vocal (consonantes / vocales) (Numérica)\n",
    "- Contiene patrones o normas ortográficas de una lengua de las que vamos a clasificar?\n",
    "    + Doble uso de vocal consecutivamente como es el caso del inglés (Categórica)\n",
    "    + Acentos en caso de catalán (Categórica)\n",
    "    + Contiene combinaciones de consonantes (consonant clusters) propias del inglés? (Categórica)\n",
    "\n",
    "Referencias\n",
    "- <Consonant_Clusters :https://www.aprendeinglessila.com/2013/09/consonantes-ingles-clusters/>\n",
    "- <Frecuencia_De_Letras_Usadas_En_Catalan: https://es.sttmedia.com/frecuencias-de-letras-catalan>\n",
    "- <Frecuencia_De_Letras_Usadas_En_Catalan: https://www3.nd.edu/~busiforc/handouts/cryptography/letterfrequencies.html>\n",
    "\n",
    "Para añadir las columnas que representen estas características, hemos aplicado las siguientes funciones a las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.to_string of           word     ratio  cantidadLetras  gotAccent  doubleVocal  enCC       y\n",
      "0      suggest  0.285714               7          0            0     0  angles\n",
      "1         came  0.500000               4          0            0     0  angles\n",
      "2      planeta  0.428571               7          0            0     0  catala\n",
      "3     finestra  0.375000               8          0            0     0  catala\n",
      "4        saber  0.400000               5          0            0     0  catala\n",
      "...        ...       ...             ...        ...          ...   ...     ...\n",
      "1971       box  0.333333               3          0            0     0  angles\n",
      "1972     ready  0.400000               5          0            0     0  angles\n",
      "1973      amic  0.500000               4          0            0     0  catala\n",
      "1974   believe  0.571429               7          0            0     0  angles\n",
      "1975        am  0.500000               2          0            0     0  angles\n",
      "\n",
      "[1976 rows x 7 columns]>\n"
     ]
    }
   ],
   "source": [
    "#ratio de consonantes y vocales\n",
    "def ratio (word):\n",
    "    vocals=0\n",
    "    for c in word:\n",
    "        if isVocal(c):\n",
    "            vocals+=1\n",
    "    return vocals/len(word) \n",
    "\n",
    "#isVocal?\n",
    "def isVocal(c):\n",
    "    if(c=='a' or c=='e' or c=='i' or c=='o' or c=='u'):\n",
    "        return True\n",
    "    return \n",
    "#gotAccent?\n",
    "def gotAccent(word):\n",
    "    #List containing all possible accentuated chars from Catalan\n",
    "    accentuatedChars=[ord('à'),ord('è'),ord('é'),ord('í'),ord('ò'),ord('ó'),ord('ú')]\n",
    "    for c in word:\n",
    "        if ord(c) in accentuatedChars:\n",
    "            return 1\n",
    "    return 0\n",
    "def doubleVocal(word):\n",
    "    ocurrences=[\"aa\",\"ee\",\"ii\",\"oo\",\"uu\"]\n",
    "    for oc in ocurrences:\n",
    "        if word.find(oc)!=-1:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def enCC(word):\n",
    "    ocurrences=[\"sch\",\"spl\",\"shr\",\"squ\",\"thr\",\"spr\",\"scr\",\"sph\",\"th\",\"tw\",\"sw\",\"sk\",\"sm\"]\n",
    "    for oc in ocurrences:\n",
    "        if word.find(oc)!=-1:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "#Features Adding\n",
    "wordsDF['ratio']=wordsDF['word'].apply(ratio)\n",
    "wordsDF['cantidadLetras']=wordsDF['word'].apply(len)\n",
    "wordsDF['gotAccent']=wordsDF['word'].apply(gotAccent)\n",
    "wordsDF['doubleVocal']=wordsDF['word'].apply(doubleVocal)\n",
    "wordsDF['enCC']=wordsDF['word'].apply(enCC)\n",
    "#Reorganize DF\n",
    "wordsDF=wordsDF[['word','ratio','cantidadLetras','gotAccent','doubleVocal','enCC','y']]\n",
    "wordsDF.to_csv('data/definitiveData.csv', index=False)\n",
    "print(wordsDF.to_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos\n",
    "En este problema creemos que el mejor modelo para clasificar las palabras va a ser una SVC lineal, ya que solamente debemos de clasificar entre dos clases. El kernel a usar podría ser uno lineal, aunque el RBF podría ser buena opción ya que tenemos un número de características bastante bajo en comparación al número de muestras. \n",
    "\n",
    "### Separación del conjunto de datos en entrenamiento y test\n",
    "Vamos a escoger un 2/3 para el conjunto de entrenamiento y el resto para el test. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         word     ratio  cantidadLetras  gotAccent  doubleVocal  enCC\n",
      "489      cura  0.500000               4          0            0     0\n",
      "931    beauty  0.500000               6          0            0     0\n",
      "119       get  0.333333               3          0            0     0\n",
      "611       cel  0.333333               3          0            0     0\n",
      "721     check  0.200000               5          0            0     0\n",
      "...       ...       ...             ...        ...          ...   ...\n",
      "658    simple  0.333333               6          0            0     0\n",
      "578      tant  0.250000               4          0            0     0\n",
      "1752   parlar  0.333333               6          0            0     0\n",
      "391   instant  0.285714               7          0            0     0\n",
      "1044   liquid  0.500000               6          0            0     0\n",
      "\n",
      "[1323 rows x 6 columns]\n",
      "            word     ratio  cantidadLetras  gotAccent  doubleVocal  enCC\n",
      "822        track  0.200000               5          0            0     0\n",
      "142         foto  0.500000               4          0            0     0\n",
      "1648      fruita  0.500000               6          0            0     0\n",
      "1622  localitzar  0.400000              10          0            0     0\n",
      "1214        blau  0.500000               4          0            0     0\n",
      "...          ...       ...             ...        ...          ...   ...\n",
      "1838     excepte  0.428571               7          0            0     0\n",
      "1187  aconseguit  0.500000              10          0            0     0\n",
      "1649    permetre  0.375000               8          0            0     0\n",
      "816          ser  0.333333               3          0            0     0\n",
      "252          got  0.333333               3          0            0     0\n",
      "\n",
      "[653 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#First we must separate dataframe into X and y format\n",
    "X=wordsDF.iloc[:,:6]\n",
    "y=wordsDF.iloc[:,6]\n",
    "\n",
    "#Then we separate the data frame in training and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=33)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los híperparámetros que deberemos de configurar en el modelo del SVM Lineal son:\n",
    "- _penalty_\n",
    "- _loss_\n",
    "- _C_\n",
    "- _max_iter_\n",
    "\n",
    "El resto de híperparámetros no son tan necesarios ya que no se ajustan al problema. Por ejemplo _dual_  no nos va a dar ninguna diferencia, ya que es un booleano que indica que algoritmo usar. Se usa **dual = False** cuando el número de muestras es mayor al de características, que es nuestro caso. <br>Tampoco usaremos *multi_class* ya que en este experimento solo usaremos las clases \"catalan\" y \"angles\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env-ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d372871e3639891ade210866eae78dd84bc0020d2e9bb7e839aeb62d7773342c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
