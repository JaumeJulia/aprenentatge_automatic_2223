{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Práctica 1 - Clasificación de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "#https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos\n",
    "En esta primera parte de la práctica vamos a preparar los datos para poder hacer la clasificación. Para ello haremos que cada muestra siga el siguiente formato: $C_1$ | $C_2$ | $C_3$ | .. | $C_n$ | $y$  (siendo $C$ una característica y $y$ el target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Auxiliar function that reformats df to one that is more fitting to Classification Problems\n",
    "def reformat(dataFrame):\n",
    "    if dataFrame.columns[0]==\"catala\":\n",
    "        dataFrame['y']=0\n",
    "    else:\n",
    "        dataFrame['y']=1\n",
    "    \n",
    "    dataFrame.rename(columns={dataFrame.columns[0]: 'word'}, inplace=True)\n",
    "    return dataFrame\n",
    "\n",
    "#RawData, it has been a little bit formatted before reading the csv, to facilitate the process.\n",
    "raw=pd.read_csv(\"data/data.csv\")\n",
    "#Split df\n",
    "catala, angles= raw.filter(['catala'], axis=1), raw.filter(['angles'], axis=1)\n",
    "#Reformating\n",
    "catala=reformat(catala)\n",
    "angles=reformat(angles)\n",
    "\n",
    "#Merging\n",
    "wordsDF=pd.concat([catala,angles], axis=0)\n",
    "#Shuffle the rows\n",
    "wordsDF = wordsDF.sample(frac=1).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caracterísiticas\n",
    "Las características que hemos pensado que pueden ser útiles para la clasificación de las palabras son:\n",
    "- Cantidad de caracteres (Númerica)\n",
    "- Proporción de consonantes por vocal (consonantes / vocales) (Numérica)\n",
    "- Contiene patrones o normas ortográficas de una lengua de las que vamos a clasificar?\n",
    "    + Doble uso de vocal consecutivamente como es el caso del inglés (Categórica)\n",
    "    + Acentos en caso de catalán (Categórica)\n",
    "    + Contiene combinaciones de consonantes (consonant clusters) propias del inglés? (Categórica)\n",
    "\n",
    "Referencias\n",
    "- <Consonant_Clusters :https://www.aprendeinglessila.com/2013/09/consonantes-ingles-clusters/>\n",
    "- <Frecuencia_De_Letras_Usadas_En_Catalan: https://es.sttmedia.com/frecuencias-de-letras-catalan>\n",
    "- <Frecuencia_De_Letras_Usadas_En_Catalan: https://www3.nd.edu/~busiforc/handouts/cryptography/letterfrequencies.html>\n",
    "\n",
    "Para añadir las columnas que representen estas características, hemos aplicado las siguientes funciones a las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.to_string of              word   ratio  cantidadLetras  gotAccent  doubleVocal  enCC  y\n",
      "0             cat  0.3333               3          0            0     0  0\n",
      "1          llibre  0.3333               6          0            0     0  0\n",
      "2             any  0.3333               3          0            0     0  1\n",
      "3        permetre  0.3750               8          0            0     0  0\n",
      "4           plain  0.4000               5          0            0     0  1\n",
      "...           ...     ...             ...        ...          ...   ... ..\n",
      "1971       centre  0.3333               6          0            0     0  0\n",
      "1972      between  0.4286               7          0            1     1  1\n",
      "1973      solució  0.4286               7          1            0     0  0\n",
      "1974         land  0.2500               4          0            0     0  1\n",
      "1975  multiplicar  0.3636              11          0            0     0  0\n",
      "\n",
      "[1976 rows x 7 columns]>\n"
     ]
    }
   ],
   "source": [
    "#ratio de consonantes y vocales\n",
    "def ratio (word):\n",
    "    vocals=0\n",
    "    for c in word:\n",
    "        if isVocal(c):\n",
    "            vocals+=1\n",
    "    return round(vocals/len(word), 4)\n",
    "\n",
    "#isVocal?\n",
    "def isVocal(c):\n",
    "    if(c=='a' or c=='e' or c=='i' or c=='o' or c=='u'):\n",
    "        return True\n",
    "    return \n",
    "#gotAccent?\n",
    "def gotAccent(word):\n",
    "    #List containing all possible accentuated chars from Catalan\n",
    "    accentuatedChars=[ord('à'),ord('è'),ord('é'),ord('í'),ord('ò'),ord('ó'),ord('ú')]\n",
    "    for c in word:\n",
    "        if ord(c) in accentuatedChars:\n",
    "            return 1\n",
    "    return 0\n",
    "def doubleVocal(word):\n",
    "    ocurrences=[\"aa\",\"ee\",\"ii\",\"oo\",\"uu\"]\n",
    "    for oc in ocurrences:\n",
    "        if word.find(oc)!=-1:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def enCC(word):\n",
    "    ocurrences=[\"sch\",\"spl\",\"shr\",\"squ\",\"thr\",\"spr\",\"scr\",\"sph\",\"th\",\"tw\",\"sw\",\"sk\",\"sm\"]\n",
    "    for oc in ocurrences:\n",
    "        if word.find(oc)!=-1:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "#Features Adding\n",
    "wordsDF['ratio']=wordsDF['word'].apply(ratio)\n",
    "wordsDF['cantidadLetras']=wordsDF['word'].apply(len)\n",
    "wordsDF['gotAccent']=wordsDF['word'].apply(gotAccent)\n",
    "wordsDF['doubleVocal']=wordsDF['word'].apply(doubleVocal)\n",
    "wordsDF['enCC']=wordsDF['word'].apply(enCC)\n",
    "#Reorganize DF\n",
    "wordsDF=wordsDF[['word','ratio','cantidadLetras','gotAccent','doubleVocal','enCC','y']]\n",
    "wordsDF.to_csv('data/definitiveData.csv', index=False)\n",
    "print(wordsDF.to_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación del conjunto de datos en entrenamiento y test\n",
    "Vamos a escoger dos tercios para el conjunto de entrenamiento y el resto para el test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40249248 -1.20923579]\n",
      " [-0.40249248  0.4099984 ]\n",
      " [-0.40249248 -1.20923579]\n",
      " ...\n",
      " [ 0.37096326  0.94974313]\n",
      " [-1.07855609 -0.66949106]\n",
      " [-0.15657738  3.10872205]]\n",
      "[-0.40249248 -0.40249248 -0.40249248 ...  0.37096326 -1.07855609\n",
      " -0.15657738]\n",
      "[-1.20923579  0.4099984  -1.20923579 ...  0.94974313 -0.66949106\n",
      "  3.10872205]\n",
      "         ratio  cantidadLetras  gotAccent  doubleVocal  enCC\n",
      "0    -0.402492       -1.209236          0            0     0\n",
      "1    -0.402492        0.409998          0            0     0\n",
      "2    -0.402492       -1.209236          0            0     0\n",
      "3    -0.064055        1.489488          0            0     0\n",
      "4     0.138845       -0.129746          0            0     0\n",
      "...        ...             ...        ...          ...   ...\n",
      "1971 -0.402492        0.409998          0            0     0\n",
      "1972  0.370963        0.949743          0            1     1\n",
      "1973  0.370963        0.949743          1            0     0\n",
      "1974 -1.078556       -0.669491          0            0     0\n",
      "1975 -0.156577        3.108722          0            0     0\n",
      "\n",
      "[1976 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#First we must separate dataframe into X and y format\n",
    "X=wordsDF.iloc[:,1:6]\n",
    "X_aux=wordsDF.iloc[:,1:3]\n",
    "y=wordsDF.iloc[:,6]\n",
    "#For better perfomance, we scale the data using an standard scaler\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(X_aux)\n",
    "standardData_aux = scaler.transform(X_aux)\n",
    "print(standardData_aux)\n",
    "#Ratio Standarized\n",
    "print(standardData_aux[:,0])\n",
    "#NumLletres Standarized\n",
    "print(standardData_aux[:,1])\n",
    "standardData=X\n",
    "standardData['ratio']=standardData_aux[:,0]\n",
    "standardData['cantidadLetras']=standardData_aux[:,1]\n",
    "print(standardData)\n",
    "#Then we separate the data frame in training and test (will be used in chosen model)\n",
    "X_train, X_test, y_train, y_test = train_test_split(standardData, y, test_size=0.33, random_state=33)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos\n",
    "En este problema creemos que el mejor modelo para clasificar las palabras va a ser una SVC con un kernel gaussiano (RBG) ya que tenemos un número de características bastante bajo en comparación al número de muestras. \n",
    "\n",
    "Los híperparámetros que deberemos de configurar en el modelo del SVM Lineal son:\n",
    "- _C_\n",
    "- _max\\_iter_\n",
    "- _gamma_\n",
    "\n",
    "El resto de híperparámetros no son tan necesarios ya que no se ajustan al problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo\n",
    "SVM_rbf = SVC(kernel='rbf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Cross-Validation\n",
    "Para el Nested Cross-Validation haremos lo siguiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score of Nested Cross Validation:0.644+-0.014\n",
      "The best estimator is:SVC(C=1, gamma=1, max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "hyper_grid = {\"C\":[0.1,1,10],\"max_iter\":[100,1000,10000],\"gamma\":[.01,.1,1]}\n",
    "\n",
    "inner_cv=StratifiedKFold(n_splits=3, shuffle=False)\n",
    "outer_cv=StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "search=GridSearchCV(estimator=SVM_rbf,cv=inner_cv,param_grid=hyper_grid,n_jobs=-1)\n",
    "search.fit(X_train,y_train)\n",
    "test_score=cross_val_score(search,X_train,y_train,cv=outer_cv,n_jobs=-1)\n",
    "print(f\"Mean score of Nested Cross Validation:\"f\"{test_score.mean():.3f}+-{test_score.std():.3f}\")\n",
    "print(f\"The best estimator is:\"f\"{search.best_estimator_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba del Modelo con los parámetros encontrados\n",
    "\n",
    "Una vez hemos encontrado los mejores híperparámetros para el SVM con Kernel Gaussiano, procedemos a entrenarlo y a realizar la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822    -1\n",
      "142     0\n",
      "1648    0\n",
      "1622    0\n",
      "1214    1\n",
      "       ..\n",
      "1838    0\n",
      "1187    0\n",
      "1649   -1\n",
      "816     0\n",
      "252     0\n",
      "Name: y, Length: 653, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "SVM_rbf.fit(X_train,y_train)\n",
    "y_predicted=SVM_rbf.predict(X_test)\n",
    "errores=y_predicted-y_test\n",
    "print(errores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('aprenentatge_automatic_2223')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b3ed45ef713d66eb30c4c224ecca975f6d1f36637243a303e315f56b339dc2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
