{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Práctica 1 - Clasificación de palabras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "El problema que se nos plantea en esta práctica es la clasificación, mediante un modelo basado en SVM, de las palabras de un dataset según la lengua a la que pertenecen. En primera instáncia solamente tenemos palabras del catalán y el inglés, pero se pueden añadir más palabras de otros idiomas usando librerías como [Googletrans](https://www.thepythoncode.com/article/translate-text-in-python#:~:text=Googletrans%20is%20a%20free%20and,detect%20languages%20and%20translate%20text.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Misc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from matplotlib.colors import ListedColormap\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CrossValidation\n",
    "## K-folding\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "## GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "# Model\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos\n",
    "En esta primera parte de la práctica vamos a preparar los datos para poder hacer la clasificación. Para ello haremos que cada muestra siga el siguiente formato: $C_1$ | $C_2$ | $C_3$ | .. | $C_n$ | $y$  (siendo $C$ una característica y $y$ el target).\n",
    "\n",
    "Se va a codificar $y$ con los valores \"0\" para representar la clase _catala_ y \"1\" para la clase _angles_. Si añadieramos más idiomas, simplemente seguiríamos con este formato, siendo por ejemplo _francés_ \"2\", _alemán_ \"3\", etc. Esto se conoce como [Label Encoding](https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd). Este tipo de codificación de variables categóricas nos viene como anillo al dedo, ya que no puede dar lugar a la confusión de que los números representan una jerarquía, debido a que estamos tratando con lenguas modernas (la jerarquía podría indicar lo cerca que está esa lengua de su lengua madre, el latín por ejemplo). \n",
    "\n",
    "La otra opción sería llevar a cabo Hot Encoding, lo que supondría crear más variables $y$ con los valores 1 y 0 para indicar si pertenece una palabra a un idioma. Esta aproximación nos podría acabar incrementando muchísimo la dimensionalidad del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Auxiliar function that reformats df to one that is more fitting to Classification Problems\n",
    "def reformat(dataFrame):\n",
    "    dataFrame['y']=dataFrame.columns[0]\n",
    "    \n",
    "    dataFrame.rename(columns={dataFrame.columns[0]: 'word'}, inplace=True)\n",
    "    return dataFrame\n",
    "\n",
    "#RawData, it has been a little bit formatted before reading the csv, to facilitate the process.\n",
    "raw=pd.read_csv(\"data/data.csv\")\n",
    "#Split df\n",
    "catala, angles= raw.filter(['catala'], axis=1), raw.filter(['angles'], axis=1)\n",
    "#Reformating\n",
    "catala=reformat(catala)\n",
    "angles=reformat(angles)\n",
    "\n",
    "#Merging\n",
    "wordsDF=pd.concat([catala,angles], axis=0)\n",
    "\n",
    "#Encoding variables\n",
    "wordsDF['y']=wordsDF['y'].astype('category')\n",
    "wordsDF['y']=wordsDF['y'].cat.codes\n",
    "#Shuffle the rows\n",
    "wordsDF = wordsDF.sample(frac=1).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caracterísiticas\n",
    "Las características que hemos pensado que pueden ser útiles para la clasificación de las palabras son:\n",
    "- Cantidad de caracteres (Númerica)\n",
    "- Proporción de consonantes por vocal (consonantes / vocales) (Numérica)\n",
    "- Contiene patrones o normas ortográficas de una lengua de las que vamos a clasificar?\n",
    "    + Doble uso de vocal consecutivamente como es el caso del inglés (Categórica)\n",
    "    + Acentos en caso de catalán (Categórica)\n",
    "    + Contiene combinaciones de consonantes (consonant clusters) propias del inglés? (Categórica)\n",
    "\n",
    "Referencias\n",
    "- <[Consonant_Clusters](https://www.aprendeinglessila.com/2013/09/consonantes-ingles-clusters)>\n",
    "- <[Frecuencia_De_Letras_Usadas_En_Catalan](https://es.sttmedia.com/frecuencias-de-letras-catalan)>\n",
    "- <[Frecuencia_De_Letras_Usadas_En_Catalan](https://www3.nd.edu/~busiforc/handouts/cryptography/letterfrequencies.html)>\n",
    "\n",
    "Para añadir las columnas que representen estas características, hemos aplicado las siguientes funciones a las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          word   ratio  cantidadLetras  gotAccent  doubleVocal  enCC  y\n",
      "0        spend  0.2000               5          0            0     0  0\n",
      "1       mercat  0.3333               6          0            0     0  1\n",
      "2          cas  0.3333               3          0            0     0  1\n",
      "3      observe  0.4286               7          0            0     0  0\n",
      "4     insectes  0.3750               8          0            0     0  1\n",
      "...        ...     ...             ...        ...          ...   ... ..\n",
      "1971      they  0.2500               4          0            0     1  0\n",
      "1972    planet  0.3333               6          0            0     0  0\n",
      "1973    people  0.5000               6          0            0     0  0\n",
      "1974    speech  0.3333               6          0            1     0  0\n",
      "1975       run  0.3333               3          0            0     0  0\n",
      "\n",
      "[1976 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#ratio de consonantes y vocales\n",
    "def ratio (word):\n",
    "    vocals=0\n",
    "    for c in word:\n",
    "        if isVocal(c):\n",
    "            vocals+=1\n",
    "    return round(vocals/len(word), 4)\n",
    "\n",
    "#isVocal?\n",
    "def isVocal(c):\n",
    "    if(c=='a' or c=='e' or c=='i' or c=='o' or c=='u'):\n",
    "        return True\n",
    "    return \n",
    "#gotAccent?\n",
    "def gotAccent(word):\n",
    "    #List containing all possible accentuated chars from Catalan\n",
    "    accentuatedChars=[ord('à'),ord('è'),ord('é'),ord('í'),ord('ò'),ord('ó'),ord('ú')]\n",
    "    for c in word:\n",
    "        if ord(c) in accentuatedChars:\n",
    "            return 1\n",
    "    return 0\n",
    "def doubleVocal(word):\n",
    "    ocurrences=[\"aa\",\"ee\",\"ii\",\"oo\",\"uu\"]\n",
    "    for oc in ocurrences:\n",
    "        if word.find(oc)!=-1:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def enCC(word):\n",
    "    ocurrences=[\"sch\",\"spl\",\"shr\",\"squ\",\"thr\",\"spr\",\"scr\",\"sph\",\"th\",\"tw\",\"sw\",\"sk\",\"sm\"]\n",
    "    for oc in ocurrences:\n",
    "        if word.find(oc)!=-1:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "#Features Adding\n",
    "wordsDF['ratio']=wordsDF['word'].apply(ratio)\n",
    "wordsDF['cantidadLetras']=wordsDF['word'].apply(len)\n",
    "wordsDF['gotAccent']=wordsDF['word'].apply(gotAccent)\n",
    "wordsDF['doubleVocal']=wordsDF['word'].apply(doubleVocal)\n",
    "wordsDF['enCC']=wordsDF['word'].apply(enCC)\n",
    "#Reorganize DF\n",
    "wordsDF=wordsDF[['word','ratio','cantidadLetras','gotAccent','doubleVocal','enCC','y']]\n",
    "#Write DF to csv\n",
    "wordsDF.to_csv('data/definitiveData.csv', index=False)\n",
    "#Checking\n",
    "print(wordsDF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación del conjunto de datos en entrenamiento y test\n",
    "Vamos a escoger dos tercios para el conjunto de entrenamiento y el resto para el test.\n",
    " Puntualizar que se han normalizado los datos para un mejor rendimiento del modelo. Solo se han escalado los datos numéricos, ya que sería erróneo escalar todo el dataset, con los categóricos, ya que podría dar lugar a dar menos importancia a estos últimos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we must separate dataframe into X and y format\n",
    "X=wordsDF.iloc[:,1:6]\n",
    "X_aux=wordsDF.iloc[:,1:3]\n",
    "y=wordsDF.iloc[:,6]\n",
    "\n",
    "#For better perfomance, we scale the data using an standard scaler\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(X_aux)\n",
    "standardData_aux = scaler.transform(X_aux)\n",
    "\n",
    "#Standarized DF\n",
    "standardData=X\n",
    "#Substitute standarized values in correspondent columns\n",
    "standardData['ratio']=standardData_aux[:,0]\n",
    "standardData['cantidadLetras']=standardData_aux[:,1]\n",
    "\n",
    "#Then we separate the data frame in training and test (will be used in chosen model)\n",
    "X_train, X_test, y_train, y_test = train_test_split(standardData, y, test_size=0.33, random_state=33)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos\n",
    "### Primer Modelo\n",
    "\n",
    "En este problema creemos que el mejor modelo para clasificar las palabras va a ser una SVC con un kernel gaussiano (__rbf__) ya que tenemos un número de características bastante bajo en comparación al número de muestras. Se han hecho pruebas con un kernel líneal, y si bien los resultados se acercan, el kernel gaussiano ha dado mejores resultados de media.\n",
    "\n",
    "Los híperparámetros que deberemos de configurar en el modelo del SVM son:\n",
    "- _C_: El parámetro __C__ en una SVM es un hiperparámetro que controla __la flexibilidad__ del modelo. Se utiliza para controlar el trade-off entre la complejidad del modelo y la cantidad de errores de clasificación que se permiten. Si C es un valor alto, el modelo se vuelve menos flexible y puede tender al overfitting. Si C es un valor bajo, el modelo es más flexible y permite más errores de clasificación. \n",
    "\n",
    "- _max\\_iter_: __Número máximo de iteraciones__ que se llevará acabo en el entrenamiento del modelo, para encontrar una solución óptima. Si el parámetro es muy pequeño puede que no encuentre una solución óptima y tenga un rendimiento bajo. Por lo contrario si ponemos un valor muy alto podría alargar el tiempo de entrenamiento innecesariamente, ya que una solución óptima se podría encontrar con menos iteraciones.\n",
    "\n",
    "- _gamma_: Controla el __ancho del kernel__. Cuanto mayor es su valor, menor es el ancho del kernel y viceversa. Si el kernel es muy ancho el modelo se vuelve más suave y no es tan sensible a los detalles de las muestras. \n",
    "\n",
    "El resto de híperparámetros no son tan necesarios ya que no se ajustan al problema. (Explicar algún que otro parámetro y decir por qué no es útil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "SVM_rbf = SVC(kernel='rbf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Cross-Validation\n",
    "Para elegir los mejores valores para los híperparámetros y a su vez elegir el modelo que mejor generaliza debemos de hacer uso de la técnica __Nested Cross-validation__. Esta técnica consiste en dos bucles, uno exterior y otro interior:\n",
    "- En el interior se aplica __GridSearch__, donde se extrae la configuración de híperparámetros que mejores resultados da.\n",
    "- En el exterior se hace un reentrenamiento con estos híperparámetros y se prueba el modelo con el conjunto de test correspondiente.\n",
    "\n",
    "Al final del proceso tendremos K modelos, con el score (_accuracy_ normalmente) correspondiente a cada uno.\n",
    "\n",
    "Referencias:<br>\n",
    "- <https://ploomber.io/blog/nested-cv/>\n",
    "- En este artículo se demuestra que hacer solo cross-validation puede resultar en un error de generalización optimista (debido a overfitting) \n",
    "<https://jmlr.csail.mit.edu/papers/volume11/cawley10a/cawley10a.pdf>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score of Nested cross-validation:0.652+-0.027\n"
     ]
    }
   ],
   "source": [
    "#Hyper Grid\n",
    "hyper_grid = {\"C\":[0.1,1,10],\"max_iter\":[100,1000,10000],\"gamma\":[.01,.1,1]}\n",
    "#Inner and Outer crossvalidation, following steps from :\n",
    "#https://www.analyticsvidhya.com/blog/2021/03/a-step-by-step-guide-to-nested-cross-validation/\n",
    "# and\n",
    "# https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html\n",
    "\n",
    "inner_cv=StratifiedKFold(n_splits=3, shuffle=True)\n",
    "outer_cv=StratifiedKFold(n_splits=5, shuffle=True)\n",
    "#GridSearch definition\n",
    "search=GridSearchCV(estimator=SVM_rbf,cv=inner_cv,param_grid=hyper_grid,scoring=\"accuracy\",n_jobs=-1)\n",
    "\n",
    "#Test score after nesting\n",
    "test_score=cross_val_score(search,X_train,y_train,cv=outer_cv,n_jobs=-1)\n",
    "#search.fit(X_train,y_train)\n",
    "#Printing results of Nested Cross-Validation\n",
    "print(f\"Mean score of Nested cross-validation:\"f\"{test_score.mean():.3f}+-{test_score.std():.3f}\")\n",
    "#print(f\"The best estimator is:\"f\"{search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, gamma=0.1, max_iter=1000)\n",
      "0.6597454717143102\n",
      "SVC(C=10, gamma=0.01, max_iter=1000)\n",
      "0.6493502661172633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pablo\\miniconda3\\envs\\aprenentatge_automatic_2223\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, gamma=0.1, max_iter=1000)\n",
      "0.6616099021375225\n",
      "SVC(C=1, gamma=0.1, max_iter=1000)\n",
      "0.6553352219074599\n",
      "SVC(C=10, gamma=0.01, max_iter=1000)\n",
      "0.6525023607176582\n"
     ]
    }
   ],
   "source": [
    "#CrossValidation\n",
    "inner_cv_man=StratifiedKFold(n_splits=3, shuffle=True)\n",
    "outer_cv_man=StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "#GridSearch definition\n",
    "search=GridSearchCV(estimator=SVM_rbf,cv=inner_cv,param_grid=hyper_grid,scoring=\"accuracy\",n_jobs=-1)\n",
    "aux_X=X_train.to_numpy()\n",
    "aux_y=y_train.to_numpy()\n",
    "for train, test in outer_cv_man.split(aux_X,aux_y):\n",
    "    \n",
    "    X_train_cv, y_train_cv = aux_X[train], aux_y[train]\n",
    "    X_test_cv, y_test_cv = aux_X[test], aux_y[test]\n",
    "    modelo = search.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    print(modelo.best_estimator_)\n",
    "    \n",
    "    print(modelo.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba del modelo con los parámetros encontrados\n",
    "\n",
    "Una vez hemos encontrado los mejores híperparámetros para el SVM con Kernel Gaussiano, procedemos a entrenarlo y a realizar la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rati d'acerts en el bloc de predicció: 0.6309341500765697\n"
     ]
    }
   ],
   "source": [
    "#Definition of SVM with best hyperparamters\n",
    "SVM_rbf=SVC(kernel=\"rbf\",C=0.1,max_iter=1000)\n",
    "\n",
    "#Train Model with Train set\n",
    "SVM_rbf.fit(X_train,y_train)\n",
    "\n",
    "#Predict with X_test\n",
    "y_predicted=SVM_rbf.predict(X_test)\n",
    "differences=y_predicted-y_test\n",
    "errors = np.count_nonzero(differences)\n",
    "\n",
    "#Print results\n",
    "print(f'Rati d\\'acerts en el bloc de predicció: {(len(y_predicted)-errors)/len(y_predicted)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('aprenentatge_automatic_2223')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b3ed45ef713d66eb30c4c224ecca975f6d1f36637243a303e315f56b339dc2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
