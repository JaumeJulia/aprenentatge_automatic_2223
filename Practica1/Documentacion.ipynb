{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Práctica 1 - Clasificación de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "#https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos\n",
    "En esta primera parte de la práctica vamos a preparar los datos para poder hacer la clasificación. Para ello haremos que cada muestra siga el siguiente formato: C1 | C2 | C3 | .. | CN | Y  (siendo C una característica y Y el target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Auxiliar function that reformats df to one that is more fitting to Classification Problems\n",
    "def reformat(dataFrame):\n",
    "    dataFrame['y']=dataFrame.columns[0]\n",
    "    dataFrame.rename(columns={dataFrame.columns[0]: 'word'}, inplace=True)\n",
    "    return dataFrame;\n",
    "#RawData, it has been a little bit formatted before reading the csv, to facilitate the process.\n",
    "raw=pd.read_csv(\"data/data.csv\")\n",
    "#Split df\n",
    "catala, angles= raw.filter(['catala'], axis=1), raw.filter(['angles'], axis=1)\n",
    "#Reformating\n",
    "catala=reformat(catala)\n",
    "angles=reformat(angles)\n",
    "\n",
    "#Merging\n",
    "wordsDF=pd.concat([catala,angles], axis=0)\n",
    "#Shuffle the rows\n",
    "wordsDF = wordsDF.sample(frac=1).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caracterísiticas\n",
    "Las características que hemos pensado que pueden ser útiles para la clasificación de las palabras son:\n",
    "- Cantidad de caracteres (Númerica)\n",
    "- Proporción de consonantes por vocal (consonantes / vocales) (Numérica)\n",
    "- Contiene patrones o normas ortográficas de una lengua de las que vamos a clasificar?\n",
    "    + Doble uso de vocal consecutivamente como es el caso del inglés (Categórica)\n",
    "    + Acentos en caso de catalán (Categórica)\n",
    "    + Contiene combinaciones de consonantes (consonant clusters) propias del inglés? (Categórica)\n",
    "\n",
    "Referencias\n",
    "- <Consonant_Clusters :https://www.aprendeinglessila.com/2013/09/consonantes-ingles-clusters/>\n",
    "- <Frecuencia_De_Letras_Usadas_En_Catalan: https://es.sttmedia.com/frecuencias-de-letras-catalan>\n",
    "- <Frecuencia_De_Letras_Usadas_En_Catalan: https://www3.nd.edu/~busiforc/handouts/cryptography/letterfrequencies.html>\n",
    "\n",
    "Para añadir las columnas que representen estas características, hemos aplicado las siguientes funciones a las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.to_string of           word   ratio  cantidadLetras  gotAccent  doubleVocal  enCC       y\n",
      "0       escola  0.5000               6          0            0     0  catala\n",
      "1     similars  0.3750               8          0            0     0  catala\n",
      "2          nor  0.3333               3          0            0     0  angles\n",
      "3        tocar  0.4000               5          0            0     0  catala\n",
      "4        their  0.4000               5          0            0     1  angles\n",
      "...        ...     ...             ...        ...          ...   ...     ...\n",
      "1971    excite  0.5000               6          0            0     0  angles\n",
      "1972     throw  0.2000               5          0            0     1  angles\n",
      "1973     dress  0.2000               5          0            0     0  angles\n",
      "1974     equip  0.6000               5          0            0     0  catala\n",
      "1975   qüestió  0.2857               7          1            0     0  catala\n",
      "\n",
      "[1976 rows x 7 columns]>\n"
     ]
    }
   ],
   "source": [
    "#ratio de consonantes y vocales\n",
    "def ratio (word):\n",
    "    vocals=0\n",
    "    for c in word:\n",
    "        if isVocal(c):\n",
    "            vocals+=1\n",
    "    return round(vocals/len(word), 4)\n",
    "\n",
    "#isVocal?\n",
    "def isVocal(c):\n",
    "    if(c=='a' or c=='e' or c=='i' or c=='o' or c=='u'):\n",
    "        return True\n",
    "    return \n",
    "#gotAccent?\n",
    "def gotAccent(word):\n",
    "    #List containing all possible accentuated chars from Catalan\n",
    "    accentuatedChars=[ord('à'),ord('è'),ord('é'),ord('í'),ord('ò'),ord('ó'),ord('ú')]\n",
    "    for c in word:\n",
    "        if ord(c) in accentuatedChars:\n",
    "            return 1\n",
    "    return 0\n",
    "def doubleVocal(word):\n",
    "    ocurrences=[\"aa\",\"ee\",\"ii\",\"oo\",\"uu\"]\n",
    "    for oc in ocurrences:\n",
    "        if word.find(oc)!=-1:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def enCC(word):\n",
    "    ocurrences=[\"sch\",\"spl\",\"shr\",\"squ\",\"thr\",\"spr\",\"scr\",\"sph\",\"th\",\"tw\",\"sw\",\"sk\",\"sm\"]\n",
    "    for oc in ocurrences:\n",
    "        if word.find(oc)!=-1:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "#Features Adding\n",
    "wordsDF['ratio']=wordsDF['word'].apply(ratio)\n",
    "wordsDF['cantidadLetras']=wordsDF['word'].apply(len)\n",
    "wordsDF['gotAccent']=wordsDF['word'].apply(gotAccent)\n",
    "wordsDF['doubleVocal']=wordsDF['word'].apply(doubleVocal)\n",
    "wordsDF['enCC']=wordsDF['word'].apply(enCC)\n",
    "#Reorganize DF\n",
    "wordsDF=wordsDF[['word','ratio','cantidadLetras','gotAccent','doubleVocal','enCC','y']]\n",
    "wordsDF.to_csv('data/definitiveData.csv', index=False)\n",
    "print(wordsDF.to_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación del conjunto de datos en entrenamiento y test\n",
    "Vamos a escoger dos tercios para el conjunto de entrenamiento y el resto para el test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we must separate dataframe into X and y format\n",
    "X=wordsDF.iloc[:,1:3]\n",
    "y=wordsDF.iloc[:,6]\n",
    "\n",
    "#Then we separate the data frame in training and test (will be used in chosen model)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=33)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos\n",
    "En este problema creemos que el mejor modelo para clasificar las palabras va a ser una SVC lineal, ya que solamente debemos de clasificar entre dos clases. El kernel a usar podría ser uno lineal, aunque el RBF podría ser buena opción ya que tenemos un número de características bastante bajo en comparación al número de muestras. \n",
    "\n",
    "Los híperparámetros que deberemos de configurar en el modelo del SVM Lineal son:\n",
    "- _penalty_\n",
    "- _loss_\n",
    "- _C_\n",
    "- _max_iter_\n",
    "\n",
    "El resto de híperparámetros no son tan necesarios ya que no se ajustan al problema. Por ejemplo _dual_  no nos va a dar ninguna diferencia, ya que es un booleano que indica que algoritmo usar. Se usa **dual = False** cuando el número de muestras es mayor al de características, que es nuestro caso. <br>Tampoco usaremos *multi_class* ya que en este experimento solo usaremos las clases \"catalan\" y \"angles\".\n",
    "\n",
    "Para el ajuste de estos híperparámetros haremos un _nested cross-validation_ que consiste en combinar **GridSearch** junto a **K-Folding**, pero en este caso usaremos la variación _Stratified_ para mantener una distribución balanceada de las clases en cada fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo\n",
    "SVM_Lineal = LinearSVC(loss='squared_hinge', dual=False, C=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Folding\n",
    "Lo primero que debemos de hacer es decidir qué valor de _k_ vamos a utilizar. Normalmente se utilizan valores entre 5 y 10. Vamos a probar entre estos rangos y ver qué valor nos da mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> folds=5, accuracy = 0.6083, (0.5924, 0.6228)\n",
      "-> folds=6, accuracy = 0.6073, (0.5684, 0.6413)\n",
      "-> folds=7, accuracy = 0.6063, (0.5532, 0.6431)\n",
      "-> folds=8, accuracy = 0.6073, (0.587, 0.6235)\n",
      "-> folds=9, accuracy = 0.6073, (0.5434, 0.653)\n",
      "-> folds=10, accuracy = 0.6048, (0.5482, 0.7157)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(cv):\n",
    "    #https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "    score = cross_val_score(SVM_Lineal,X,y,scoring='accuracy',cv=cv,n_jobs=-1)\n",
    "    return mean(score),score.min(),score.max()\n",
    "\n",
    "\n",
    "#Range to be tested\n",
    "folds = range (5,11)\n",
    "for k in folds:\n",
    "    #verificar si hay que tocar shuffle y dejarlo a false\n",
    "    cv=StratifiedKFold(n_splits=k, shuffle=True)\n",
    "    k_mean, k_min, k_max = evaluate_model(cv)\n",
    "    print(f'-> folds={k}, accuracy = {round(k_mean,4)}, ({round(k_min,4)}, {round(k_max,4)})')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env-ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d372871e3639891ade210866eae78dd84bc0020d2e9bb7e839aeb62d7773342c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
